{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIKETA 1 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "import codecs\n",
    "import Levenshtein\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element html at 0x17e880ac590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagina = 'https://dreguera.github.io/'\n",
    "page = requests.get(pagina)\n",
    "tree = html.fromstring(page.content)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element div at 0x17e880bdbd0>,\n",
       " <Element div at 0x17e880bdcc0>,\n",
       " <Element div at 0x17e880bdd10>,\n",
       " <Element div at 0x17e880bdd60>,\n",
       " <Element div at 0x17e880bddb0>,\n",
       " <Element div at 0x17e880bde00>,\n",
       " <Element div at 0x17e880bde50>,\n",
       " <Element div at 0x17e880bdea0>]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_a = tree.xpath(\"///div[@id='ariketa2']/div[@class='post']/div/div[@id='content']\")\n",
    "mensaje_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He estado corrigiendo los trabajos de Data Science y la parte de aprendizaje no supervisado la han realizado bastante bien, Â¿QuÃ© algoritmos de clustering has dado en clase?']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_dani1= mensaje_a[0].text.split('.')\n",
    "mensaje_dani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MeanShift para clustering por densidad habeis visto? Yo suelo utilizar para datos numÃ©ricos y me da muy buenos resultados para descartar outliers']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_dani2= mensaje_a[2].text.split('.')\n",
    "mensaje_dani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ainho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He estado corrigiendo los trabajos de Data Science y la parte de aprendizaje no supervisado la han realizado bastante bien, Â¿QuÃ© algoritmos de clustering has dado en clase?',\n",
       " 'MeanShift para clustering por densidad habeis visto? Yo suelo utilizar para datos numÃ©ricos y me da muy buenos resultados para descartar outliers']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mensajes= mensaje_dani1 + mensaje_dani2\n",
    "# mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_docsa=[]\n",
    "file_docs2a=[]\n",
    "tokens = sent_tokenize(mensaje_dani1[0])\n",
    "for line in tokens:\n",
    "    file_docsa.append(line)\n",
    "    \n",
    "tokens = sent_tokenize(mensaje_dani2[0])\n",
    "for line in tokens:\n",
    "    file_docs2a.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He estado corrigiendo los trabajos de Data Science y la parte de aprendizaje no supervisado la han realizado bastante bien, Â¿QuÃ© algoritmos de clustering has dado en clase?']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_docsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MeanShift para clustering por densidad habeis visto?',\n",
       " 'Yo suelo utilizar para datos numÃ©ricos y me da muy buenos resultados para descartar outliers']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_docs2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He estado corrigiendo los trabajos de Data Science y la parte de aprendizaje no supervisado la han realizado bastante bien, Â¿QuÃ© algoritmos de clustering has dado en clase?']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajes_lista[0].split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MeanShift para clustering por densidad habeis visto? Yo suelo utilizar para datos numÃ©ricos y me da muy buenos resultados para descartar outliers']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajes_lista[1].split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'dani',\n",
       "  ',',\n",
       "  'en',\n",
       "  'la',\n",
       "  'parte',\n",
       "  'de',\n",
       "  'no',\n",
       "  'supervisado',\n",
       "  'me',\n",
       "  'he',\n",
       "  'centrado',\n",
       "  'sobre',\n",
       "  'todo',\n",
       "  'en',\n",
       "  'el',\n",
       "  'clustering',\n",
       "  'por',\n",
       "  'densidad',\n",
       "  '.'],\n",
       " ['hemos', 'visto', 'optics', ',', 'dbscan', 'y', 'hdscan']]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docsa = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs]\n",
    "gen_docsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['el',\n",
       "  'tema',\n",
       "  'del',\n",
       "  'clutering',\n",
       "  'por',\n",
       "  'densidad',\n",
       "  'me',\n",
       "  'parece',\n",
       "  'super',\n",
       "  'interesante',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'se',\n",
       "  'si',\n",
       "  'tendrã\\xada',\n",
       "  'aplicabilidad',\n",
       "  'en',\n",
       "  'el',\n",
       "  'reto',\n",
       "  '7']]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docs2a = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs2]\n",
    "gen_docs2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, '.': 1, 'centrado': 2, 'clustering': 3, 'dani': 4, 'de': 5, 'densidad': 6, 'el': 7, 'en': 8, 'he': 9, 'hola': 10, 'la': 11, 'me': 12, 'no': 13, 'parte': 14, 'por': 15, 'sobre': 16, 'supervisado': 17, 'todo': 18, 'dbscan': 19, 'hdscan': 20, 'hemos': 21, 'optics': 22, 'visto': 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "dictionarya = gensim.corpora.Dictionary(gen_docsa)\n",
    "print(dictionarya.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 2),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1)],\n",
       " [(0, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusa = [dictionarya.doc2bow(gen_doca) for gen_doca in gen_docsa]\n",
    "corpusa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfa = gensim.models.TfidfModel(corpusa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsa = gensim.similarities.Similarity('a',tf_idfa[corpusa],\n",
    "                                        num_features=len(dictionarya))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file_docs2a:\n",
    "    query_doca = [w.lower() for w in word_tokenize(line)]\n",
    "    query_doc_bowa = dictionarya.doc2bow(query_doca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idfa = tf_idfa[query_doc_bowa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.15430336 0.28867513]\n"
     ]
    }
   ],
   "source": [
    "print('Comparing Result:', simsa[query_doc_tf_idfa]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4429785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sum_of_simsa =(np.sum(simsa[query_doc_tf_idfa], dtype=np.float32))\n",
    "print(sum_of_simsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity percentage: 44.297850131988525\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Average similarity percentage: {float(sum_of_simsa / len(file_docsa)) * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIKETA 1 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mensajeb = tree.xpath(\"///div[@id='ariketa2']/div[@class='post']/div/div[@id='content']\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola Dani, en la parte de no supervisado me he centrado sobre todo en el clustering por densidad. Hemos visto Optics, DBSCAN y HDSCAN']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_carlos1 = mensajeb[1].text.split(' ., ')\n",
    "mensaje_carlos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Si, la verdad es que da buenos resultados pero cuando si puedes hacer ajustes manuales de otros parÃ¡metros, OPTICS y DBSCAN son mÃ¡s Ã³ptimos']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_carlos2= mensajeb[3].text.split('.')\n",
    "mensaje_carlos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ainho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_docsb=[]\n",
    "file_docs2b=[]\n",
    "tokens = sent_tokenize(mensaje_carlos1[0])\n",
    "for line in tokens:\n",
    "    file_docsb.append(line)\n",
    "    \n",
    "tokens = sent_tokenize(mensaje_carlos2[0])\n",
    "for line in tokens:\n",
    "    file_docs2b.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola Dani, en la parte de no supervisado me he centrado sobre todo en el clustering por densidad.',\n",
       " 'Hemos visto Optics, DBSCAN y HDSCAN']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_docsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Si, la verdad es que da buenos resultados pero cuando si puedes hacer ajustes manuales de otros parÃ¡metros, OPTICS y DBSCAN son mÃ¡s Ã³ptimos']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_docs2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'dani',\n",
       "  ',',\n",
       "  'en',\n",
       "  'la',\n",
       "  'parte',\n",
       "  'de',\n",
       "  'no',\n",
       "  'supervisado',\n",
       "  'me',\n",
       "  'he',\n",
       "  'centrado',\n",
       "  'sobre',\n",
       "  'todo',\n",
       "  'en',\n",
       "  'el',\n",
       "  'clustering',\n",
       "  'por',\n",
       "  'densidad',\n",
       "  '.'],\n",
       " ['hemos', 'visto', 'optics', ',', 'dbscan', 'y', 'hdscan']]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docsb = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs]\n",
    "gen_docsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['si',\n",
       "  ',',\n",
       "  'la',\n",
       "  'verdad',\n",
       "  'es',\n",
       "  'que',\n",
       "  'da',\n",
       "  'buenos',\n",
       "  'resultados',\n",
       "  'pero',\n",
       "  'cuando',\n",
       "  'si',\n",
       "  'puedes',\n",
       "  'hacer',\n",
       "  'ajustes',\n",
       "  'manuales',\n",
       "  'de',\n",
       "  'otros',\n",
       "  'parã¡metros',\n",
       "  ',',\n",
       "  'optics',\n",
       "  'y',\n",
       "  'dbscan',\n",
       "  'son',\n",
       "  'mã¡s',\n",
       "  'ã³ptimos']]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docs2b = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs2b]\n",
    "gen_docs2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, '.': 1, 'centrado': 2, 'clustering': 3, 'dani': 4, 'de': 5, 'densidad': 6, 'el': 7, 'en': 8, 'he': 9, 'hola': 10, 'la': 11, 'me': 12, 'no': 13, 'parte': 14, 'por': 15, 'sobre': 16, 'supervisado': 17, 'todo': 18, 'dbscan': 19, 'hdscan': 20, 'hemos': 21, 'optics': 22, 'visto': 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "dictionaryb = gensim.corpora.Dictionary(gen_docsb)\n",
    "print(dictionaryb.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 2),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1)],\n",
       " [(0, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusb = [dictionary.doc2bow(gen_docb) for gen_docb in gen_docsb]\n",
    "corpusb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfb = gensim.models.TfidfModel(corpusb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsb = gensim.similarities.Similarity('a',tf_idfb[corpusb],\n",
    "                                        num_features=len(dictionaryb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file_docs2b:\n",
    "    query_docb = [w.lower() for w in word_tokenize(line)]\n",
    "    query_doc_bowb = dictionaryb.doc2bow(query_docb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idfb = tf_idfb[query_doc_bowb]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.19518001 0.5477226 ]\n"
     ]
    }
   ],
   "source": [
    "print('Comparing Result:', simsb[query_doc_tf_idfb]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7429026\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sum_of_simsb =(np.sum(simsb[query_doc_tf_idfb], dtype=np.float32))\n",
    "print(sum_of_simsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity percentage: 37.14512884616852\n"
     ]
    }
   ],
   "source": [
    "print(f'Average similarity percentage: {float(sum_of_simsb / len(file_docsb)) * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIKETA 1 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajec = tree.xpath(\"///div[@id='ariketa2']/div[@class='post']/div/div[@id='content']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola Dani, en la parte de no supervisado me he centrado sobre todo en el clustering por densidad. Hemos visto Optics, DBSCAN y HDSCAN']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_carlos1 = mensajec[1].text.split(' . ')\n",
    "mensaje_carlos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El tema del clutering por densidad me parece super interesante pero no se si tendrÃ\\xada aplicabilidad en el Reto 7']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensaje_sara1 = mensajec[4].text.split(' . ')\n",
    "mensaje_sara1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_docsc=[]\n",
    "file_docs2c=[]\n",
    "tokens = sent_tokenize(mensaje_carlos1[0])\n",
    "for line in tokens:\n",
    "    file_docsc.append(line)\n",
    "    \n",
    "tokens = sent_tokenize(mensaje_sara1[0])\n",
    "for line in tokens:\n",
    "    file_docs2c.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hola',\n",
       "  'dani',\n",
       "  ',',\n",
       "  'en',\n",
       "  'la',\n",
       "  'parte',\n",
       "  'de',\n",
       "  'no',\n",
       "  'supervisado',\n",
       "  'me',\n",
       "  'he',\n",
       "  'centrado',\n",
       "  'sobre',\n",
       "  'todo',\n",
       "  'en',\n",
       "  'el',\n",
       "  'clustering',\n",
       "  'por',\n",
       "  'densidad',\n",
       "  '.'],\n",
       " ['hemos', 'visto', 'optics', ',', 'dbscan', 'y', 'hdscan']]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docsc = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docsc]\n",
    "gen_docsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['el',\n",
       "  'tema',\n",
       "  'del',\n",
       "  'clutering',\n",
       "  'por',\n",
       "  'densidad',\n",
       "  'me',\n",
       "  'parece',\n",
       "  'super',\n",
       "  'interesante',\n",
       "  'pero',\n",
       "  'no',\n",
       "  'se',\n",
       "  'si',\n",
       "  'tendrã\\xada',\n",
       "  'aplicabilidad',\n",
       "  'en',\n",
       "  'el',\n",
       "  'reto',\n",
       "  '7']]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docs2c = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in file_docs2c]\n",
    "gen_docs2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': 0, '.': 1, 'centrado': 2, 'clustering': 3, 'dani': 4, 'de': 5, 'densidad': 6, 'el': 7, 'en': 8, 'he': 9, 'hola': 10, 'la': 11, 'me': 12, 'no': 13, 'parte': 14, 'por': 15, 'sobre': 16, 'supervisado': 17, 'todo': 18, 'dbscan': 19, 'hdscan': 20, 'hemos': 21, 'optics': 22, 'visto': 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "dictionaryc= gensim.corpora.Dictionary(gen_docsc)\n",
    "print(dictionaryc.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 1),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 2),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1)],\n",
       " [(0, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusc = [dictionaryc.doc2bow(gen_docc) for gen_docc in gen_docsc]\n",
    "corpusc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfc = gensim.models.TfidfModel(corpusc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "simsc = gensim.similarities.Similarity('a',tf_idfc[corpusc],\n",
    "                                        num_features=len(dictionaryc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file_docs2c:\n",
    "    query_docc = [w.lower() for w in word_tokenize(line)]\n",
    "    query_doc_bowc = dictionaryc.doc2bow(query_docc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_tf_idfc = tf_idfc[query_doc_bowc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Result: [0.5819144 0.       ]\n"
     ]
    }
   ],
   "source": [
    "print('Comparing Result:', simsc[query_doc_tf_idfc]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5819144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sum_of_simsc =(np.sum(simsc[query_doc_tf_idfc], dtype=np.float32))\n",
    "print(sum_of_simsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity percentage: 29.09572124481201\n"
     ]
    }
   ],
   "source": [
    "print(f'Average similarity percentage: {float(sum_of_simsc / len(file_docsc)) * 100}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIKETA 1 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_vectors(vec1,vec2):\n",
    "    vec1 = vec1.reshape(1,-1)\n",
    "    vec2 = vec2.reshape(1,-1)\n",
    "    return cosine_similarity(vec1,vec2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim_vectors(vectors[2],vectors[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIKETA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ainho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ainho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import codecs\n",
    "from lxml import html\n",
    "import gensim\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Top Genre</th>\n",
       "      <th>Year</th>\n",
       "      <th>Beats Per Minute (BPM)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Loudness (dB)</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Length (Duration)</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Norah Jones</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>2004</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>-14</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>201</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Night</td>\n",
       "      <td>Deep Purple</td>\n",
       "      <td>album rock</td>\n",
       "      <td>2000</td>\n",
       "      <td>135</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>-11</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>207</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clint Eastwood</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>alternative hip hop</td>\n",
       "      <td>2001</td>\n",
       "      <td>168</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>341</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Pretender</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>alternative metal</td>\n",
       "      <td>2007</td>\n",
       "      <td>173</td>\n",
       "      <td>96</td>\n",
       "      <td>43</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waitin' On A Sunny Day</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>classic rock</td>\n",
       "      <td>2002</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>-5</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1990</td>\n",
       "      <td>Heartbreak Hotel</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1958</td>\n",
       "      <td>94</td>\n",
       "      <td>21</td>\n",
       "      <td>70</td>\n",
       "      <td>-12</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1991</td>\n",
       "      <td>Hound Dog</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1958</td>\n",
       "      <td>175</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>-8</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>136</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1992</td>\n",
       "      <td>Johnny B. Goode</td>\n",
       "      <td>Chuck Berry</td>\n",
       "      <td>blues rock</td>\n",
       "      <td>1959</td>\n",
       "      <td>168</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>-9</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>162</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1993</td>\n",
       "      <td>Take Five</td>\n",
       "      <td>The Dave Brubeck Quartet</td>\n",
       "      <td>bebop</td>\n",
       "      <td>1959</td>\n",
       "      <td>174</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>-13</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>324</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1994</td>\n",
       "      <td>Blueberry Hill</td>\n",
       "      <td>Fats Domino</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1959</td>\n",
       "      <td>133</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>-10</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>148</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index                   Title                    Artist  \\\n",
       "0         1                 Sunrise               Norah Jones   \n",
       "1         2             Black Night               Deep Purple   \n",
       "2         3          Clint Eastwood                  Gorillaz   \n",
       "3         4           The Pretender              Foo Fighters   \n",
       "4         5  Waitin' On A Sunny Day         Bruce Springsteen   \n",
       "...     ...                     ...                       ...   \n",
       "1989   1990        Heartbreak Hotel             Elvis Presley   \n",
       "1990   1991               Hound Dog             Elvis Presley   \n",
       "1991   1992         Johnny B. Goode               Chuck Berry   \n",
       "1992   1993               Take Five  The Dave Brubeck Quartet   \n",
       "1993   1994          Blueberry Hill               Fats Domino   \n",
       "\n",
       "                Top Genre  Year  Beats Per Minute (BPM)  Energy  Danceability  \\\n",
       "0         adult standards  2004                     157      30            53   \n",
       "1              album rock  2000                     135      79            50   \n",
       "2     alternative hip hop  2001                     168      69            66   \n",
       "3       alternative metal  2007                     173      96            43   \n",
       "4            classic rock  2002                     106      82            58   \n",
       "...                   ...   ...                     ...     ...           ...   \n",
       "1989      adult standards  1958                      94      21            70   \n",
       "1990      adult standards  1958                     175      76            36   \n",
       "1991           blues rock  1959                     168      80            53   \n",
       "1992                bebop  1959                     174      26            45   \n",
       "1993      adult standards  1959                     133      50            49   \n",
       "\n",
       "      Loudness (dB)  Liveness  Valence Length (Duration)  Acousticness  \\\n",
       "0               -14        11       68               201            94   \n",
       "1               -11        17       81               207            17   \n",
       "2                -9         7       52               341             2   \n",
       "3                -4         3       37               269             0   \n",
       "4                -5        10       87               256             1   \n",
       "...             ...       ...      ...               ...           ...   \n",
       "1989            -12        11       72               128            84   \n",
       "1990             -8        76       95               136            73   \n",
       "1991             -9        31       97               162            74   \n",
       "1992            -13         7       60               324            54   \n",
       "1993            -10        16       83               148            74   \n",
       "\n",
       "      Speechiness  Popularity  \n",
       "0               3          71  \n",
       "1               7          39  \n",
       "2              17          69  \n",
       "3               4          76  \n",
       "4               3          59  \n",
       "...           ...         ...  \n",
       "1989            7          63  \n",
       "1990            6          69  \n",
       "1991            7          74  \n",
       "1992            4          65  \n",
       "1993            3          56  \n",
       "\n",
       "[1994 rows x 15 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Spotify-2000.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titulo_artista(row):\n",
    "    return row['Artist']+\" \"+row['Top Genre']\n",
    "df[\"titulo_artista\"] = df.apply(combined_features, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Top Genre</th>\n",
       "      <th>Year</th>\n",
       "      <th>Beats Per Minute (BPM)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Loudness (dB)</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Length (Duration)</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>titulo_artista</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Norah Jones</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>2004</td>\n",
       "      <td>157</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>-14</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>201</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>Norah Jones adult standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Night</td>\n",
       "      <td>Deep Purple</td>\n",
       "      <td>album rock</td>\n",
       "      <td>2000</td>\n",
       "      <td>135</td>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>-11</td>\n",
       "      <td>17</td>\n",
       "      <td>81</td>\n",
       "      <td>207</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>Deep Purple album rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clint Eastwood</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>alternative hip hop</td>\n",
       "      <td>2001</td>\n",
       "      <td>168</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>-9</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>341</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>Gorillaz alternative hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Pretender</td>\n",
       "      <td>Foo Fighters</td>\n",
       "      <td>alternative metal</td>\n",
       "      <td>2007</td>\n",
       "      <td>173</td>\n",
       "      <td>96</td>\n",
       "      <td>43</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>Foo Fighters alternative metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waitin' On A Sunny Day</td>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>classic rock</td>\n",
       "      <td>2002</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>-5</td>\n",
       "      <td>10</td>\n",
       "      <td>87</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>Bruce Springsteen classic rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1990</td>\n",
       "      <td>Heartbreak Hotel</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1958</td>\n",
       "      <td>94</td>\n",
       "      <td>21</td>\n",
       "      <td>70</td>\n",
       "      <td>-12</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>128</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>Elvis Presley adult standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1991</td>\n",
       "      <td>Hound Dog</td>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1958</td>\n",
       "      <td>175</td>\n",
       "      <td>76</td>\n",
       "      <td>36</td>\n",
       "      <td>-8</td>\n",
       "      <td>76</td>\n",
       "      <td>95</td>\n",
       "      <td>136</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>Elvis Presley adult standards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1992</td>\n",
       "      <td>Johnny B. Goode</td>\n",
       "      <td>Chuck Berry</td>\n",
       "      <td>blues rock</td>\n",
       "      <td>1959</td>\n",
       "      <td>168</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>-9</td>\n",
       "      <td>31</td>\n",
       "      <td>97</td>\n",
       "      <td>162</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>Chuck Berry blues rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1993</td>\n",
       "      <td>Take Five</td>\n",
       "      <td>The Dave Brubeck Quartet</td>\n",
       "      <td>bebop</td>\n",
       "      <td>1959</td>\n",
       "      <td>174</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>-13</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>324</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>The Dave Brubeck Quartet bebop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1994</td>\n",
       "      <td>Blueberry Hill</td>\n",
       "      <td>Fats Domino</td>\n",
       "      <td>adult standards</td>\n",
       "      <td>1959</td>\n",
       "      <td>133</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>-10</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>148</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>Fats Domino adult standards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1994 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index                   Title                    Artist  \\\n",
       "0         1                 Sunrise               Norah Jones   \n",
       "1         2             Black Night               Deep Purple   \n",
       "2         3          Clint Eastwood                  Gorillaz   \n",
       "3         4           The Pretender              Foo Fighters   \n",
       "4         5  Waitin' On A Sunny Day         Bruce Springsteen   \n",
       "...     ...                     ...                       ...   \n",
       "1989   1990        Heartbreak Hotel             Elvis Presley   \n",
       "1990   1991               Hound Dog             Elvis Presley   \n",
       "1991   1992         Johnny B. Goode               Chuck Berry   \n",
       "1992   1993               Take Five  The Dave Brubeck Quartet   \n",
       "1993   1994          Blueberry Hill               Fats Domino   \n",
       "\n",
       "                Top Genre  Year  Beats Per Minute (BPM)  Energy  Danceability  \\\n",
       "0         adult standards  2004                     157      30            53   \n",
       "1              album rock  2000                     135      79            50   \n",
       "2     alternative hip hop  2001                     168      69            66   \n",
       "3       alternative metal  2007                     173      96            43   \n",
       "4            classic rock  2002                     106      82            58   \n",
       "...                   ...   ...                     ...     ...           ...   \n",
       "1989      adult standards  1958                      94      21            70   \n",
       "1990      adult standards  1958                     175      76            36   \n",
       "1991           blues rock  1959                     168      80            53   \n",
       "1992                bebop  1959                     174      26            45   \n",
       "1993      adult standards  1959                     133      50            49   \n",
       "\n",
       "      Loudness (dB)  Liveness  Valence Length (Duration)  Acousticness  \\\n",
       "0               -14        11       68               201            94   \n",
       "1               -11        17       81               207            17   \n",
       "2                -9         7       52               341             2   \n",
       "3                -4         3       37               269             0   \n",
       "4                -5        10       87               256             1   \n",
       "...             ...       ...      ...               ...           ...   \n",
       "1989            -12        11       72               128            84   \n",
       "1990             -8        76       95               136            73   \n",
       "1991             -9        31       97               162            74   \n",
       "1992            -13         7       60               324            54   \n",
       "1993            -10        16       83               148            74   \n",
       "\n",
       "      Speechiness  Popularity                  titulo_artista  \n",
       "0               3          71     Norah Jones adult standards  \n",
       "1               7          39          Deep Purple album rock  \n",
       "2              17          69    Gorillaz alternative hip hop  \n",
       "3               4          76  Foo Fighters alternative metal  \n",
       "4               3          59  Bruce Springsteen classic rock  \n",
       "...           ...         ...                             ...  \n",
       "1989            7          63   Elvis Presley adult standards  \n",
       "1990            6          69   Elvis Presley adult standards  \n",
       "1991            7          74          Chuck Berry blues rock  \n",
       "1992            4          65  The Dave Brubeck Quartet bebop  \n",
       "1993            3          56     Fats Domino adult standards  \n",
       "\n",
       "[1994 rows x 16 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit_transform(df[\"titulo_artista\"])\n",
    "vectors = vectorizer.toarray()\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  , ..., 0.  , 0.  , 0.5 ],\n",
       "       [0.  , 1.  , 0.  , ..., 0.25, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 0.25, 0.  , ..., 1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , ..., 0.  , 1.  , 0.  ],\n",
       "       [0.5 , 0.  , 0.  , ..., 0.  , 0.  , 1.  ]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csim=cosine_similarity(vectors)\n",
    "csim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_from_title(Title):\n",
    "    return df[df.Title == Title][\"Index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3\n",
       "Name: Index, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_index= get_index_from_title('Clint Eastwood')\n",
    "c_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([0.  , 0.  , 0.25, ..., 0.  , 0.  , 0.  ]))]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_similar = list(enumerate(csim[c_index])) \n",
    "c_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([0.  , 0.  , 0.25, ..., 0.  , 0.  , 0.  ]))]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_similar_c = sorted(c_similar, key=lambda x:x[1], reverse=True)\n",
    "sorted_similar_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clint Eastwood'"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_title_from_index(Index):\n",
    "    return df[df.Index == Index][\"Title\"].values[0]\n",
    "get_title_from_index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gorillaz'"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_title_from_index1(Index):\n",
    "    return df[df.Index == Index][\"Artist\"].values[0]\n",
    "get_title_from_index1(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black Night->Deep Purple',\n",
       " 'Clint Eastwood->Gorillaz',\n",
       " 'The Pretender->Foo Fighters',\n",
       " \"Waitin' On A Sunny Day->Bruce Springsteen\",\n",
       " 'The Road Ahead (Miles Of The Unknown)->City To City']"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=get_title_from_index(2)\n",
    "b=get_title_from_index(3)\n",
    "c=get_title_from_index(4)\n",
    "d=get_title_from_index(5)\n",
    "e=get_title_from_index(6)\n",
    "\n",
    "g=get_title_from_index1(2)\n",
    "h=get_title_from_index1(3)\n",
    "i=get_title_from_index1(4)\n",
    "j=get_title_from_index1(5)\n",
    "k=get_title_from_index1(6)\n",
    "\n",
    "\n",
    "f= a+('->') +g+(',')+b+('->') + h+(',')+c+ ('->') +i+(',')+d+('->') + j+(',')+e+('->') + k\n",
    "f.split(',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
